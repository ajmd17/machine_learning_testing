<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>GradientBoostingClassifier.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">JPMML-SkLearn</a> &gt; <a href="index.source.html" class="el_package">sklearn.ensemble.gradient_boosting</a> &gt; <span class="el_source">GradientBoostingClassifier.java</span></div><h1>GradientBoostingClassifier.java</h1><pre class="source lang-java linenums">/*
 * Copyright (c) 2015 Villu Ruusmann
 *
 * This file is part of JPMML-SkLearn
 *
 * JPMML-SkLearn is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * JPMML-SkLearn is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with JPMML-SkLearn.  If not, see &lt;http://www.gnu.org/licenses/&gt;.
 */
package sklearn.ensemble.gradient_boosting;

import java.util.ArrayList;
import java.util.List;

import org.dmg.pmml.DataType;
import org.dmg.pmml.FieldName;
import org.dmg.pmml.OpType;
import org.dmg.pmml.mining.MiningModel;
import org.dmg.pmml.regression.RegressionModel;
import org.jpmml.converter.CMatrixUtil;
import org.jpmml.converter.CategoricalLabel;
import org.jpmml.converter.ContinuousLabel;
import org.jpmml.converter.ModelUtil;
import org.jpmml.converter.Schema;
import org.jpmml.converter.ValueUtil;
import org.jpmml.converter.mining.MiningModelUtil;
import org.jpmml.sklearn.ClassDictUtil;
import org.jpmml.sklearn.TreeModelProducer;
import sklearn.Classifier;
import sklearn.EstimatorUtil;
import sklearn.tree.DecisionTreeRegressor;

public class GradientBoostingClassifier extends Classifier implements TreeModelProducer {

	public GradientBoostingClassifier(String module, String name){
<span class="fc" id="L45">		super(module, name);</span>
<span class="fc" id="L46">	}</span>

	@Override
	public int getNumberOfFeatures(){

		// SkLearn 0.18
<span class="pc bpc" id="L52" title="1 of 2 branches missed.">		if(containsKey(&quot;n_features&quot;)){</span>
<span class="nc" id="L53">			return ValueUtil.asInt((Number)get(&quot;n_features&quot;));</span>
		}

		// SkLearn 0.19+
<span class="fc" id="L57">		return super.getNumberOfFeatures();</span>
	}

	@Override
	public DataType getDataType(){
<span class="nc" id="L62">		return DataType.FLOAT;</span>
	}

	@Override
	public MiningModel encodeModel(Schema schema){
<span class="fc" id="L67">		LossFunction loss = getLoss();</span>

<span class="fc" id="L69">		int numberOfClasses = loss.getK();</span>

<span class="fc" id="L71">		HasPriorProbability init = getInit();</span>

<span class="fc" id="L73">		Number learningRate = getLearningRate();</span>

<span class="fc" id="L75">		List&lt;DecisionTreeRegressor&gt; estimators = getEstimators();</span>

<span class="fc" id="L77">		Schema segmentSchema = new Schema(new ContinuousLabel(null, DataType.DOUBLE), schema.getFeatures());</span>

<span class="fc" id="L79">		CategoricalLabel categoricalLabel = (CategoricalLabel)schema.getLabel();</span>

<span class="fc bfc" id="L81" title="All 2 branches covered.">		if(numberOfClasses == 1){</span>
<span class="fc" id="L82">			EstimatorUtil.checkSize(2, categoricalLabel);</span>

<span class="fc" id="L84">			MiningModel miningModel = GradientBoostingUtil.encodeGradientBoosting(estimators, init.getPriorProbability(0), learningRate, segmentSchema)</span>
<span class="fc" id="L85">				.setOutput(ModelUtil.createPredictedOutput(FieldName.create(&quot;decisionFunction(&quot; + categoricalLabel.getValue(1) + &quot;)&quot;), OpType.CONTINUOUS, DataType.DOUBLE, loss.createTransformation()));</span>

<span class="fc" id="L87">			return MiningModelUtil.createBinaryLogisticClassification(miningModel, 1d, 0d, RegressionModel.NormalizationMethod.NONE, true, schema);</span>
		} else

<span class="pc bpc" id="L90" title="1 of 2 branches missed.">		if(numberOfClasses &gt;= 3){</span>
<span class="fc" id="L91">			EstimatorUtil.checkSize(numberOfClasses, categoricalLabel);</span>

<span class="fc" id="L93">			List&lt;MiningModel&gt; miningModels = new ArrayList&lt;&gt;();</span>

<span class="fc bfc" id="L95" title="All 2 branches covered.">			for(int i = 0, columns = categoricalLabel.size(), rows = (estimators.size() / columns); i &lt; columns; i++){</span>
<span class="fc" id="L96">				MiningModel miningModel = GradientBoostingUtil.encodeGradientBoosting(CMatrixUtil.getColumn(estimators, rows, columns, i), init.getPriorProbability(i), learningRate, segmentSchema)</span>
<span class="fc" id="L97">					.setOutput(ModelUtil.createPredictedOutput(FieldName.create(&quot;decisionFunction(&quot; + categoricalLabel.getValue(i) + &quot;)&quot;), OpType.CONTINUOUS, DataType.DOUBLE, loss.createTransformation()));</span>

<span class="fc" id="L99">				miningModels.add(miningModel);</span>
			}

<span class="fc" id="L102">			return MiningModelUtil.createClassification(miningModels, RegressionModel.NormalizationMethod.SIMPLEMAX, true, schema);</span>
		} else

		{
<span class="nc" id="L106">			throw new IllegalArgumentException();</span>
		}
	}

	public LossFunction getLoss(){
<span class="fc" id="L111">		Object loss = get(&quot;loss_&quot;);</span>

		try {
<span class="pc bpc" id="L114" title="1 of 2 branches missed.">			if(loss == null){</span>
<span class="nc" id="L115">				throw new NullPointerException();</span>
			}

<span class="fc" id="L118">			return (LossFunction)loss;</span>
<span class="nc" id="L119">		} catch(RuntimeException re){</span>
<span class="nc" id="L120">			throw new IllegalArgumentException(&quot;The loss function object (&quot; + ClassDictUtil.formatClass(loss) + &quot;) is not a LossFunction or is not a supported LossFunction subclass&quot;, re);</span>
		}
	}

	public HasPriorProbability getInit(){
<span class="fc" id="L125">		Object init = get(&quot;init_&quot;);</span>

		try {
<span class="pc bpc" id="L128" title="1 of 2 branches missed.">			if(init == null){</span>
<span class="nc" id="L129">				throw new NullPointerException();</span>
			}

<span class="fc" id="L132">			return (HasPriorProbability)init;</span>
<span class="nc" id="L133">		} catch(RuntimeException re){</span>
<span class="nc" id="L134">			throw new IllegalArgumentException(&quot;The estimator object (&quot; + ClassDictUtil.formatClass(init) + &quot;) is not a BaseEstimator or is not a supported BaseEstimator subclass&quot;, re);</span>
		}
	}

	public Number getLearningRate(){
<span class="fc" id="L139">		return (Number)get(&quot;learning_rate&quot;);</span>
	}

	public List&lt;DecisionTreeRegressor&gt; getEstimators(){
<span class="fc" id="L143">		return (List)ClassDictUtil.getArray(this, &quot;estimators_&quot;);</span>
	}
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.7.9.201702052155</span></div></body></html>